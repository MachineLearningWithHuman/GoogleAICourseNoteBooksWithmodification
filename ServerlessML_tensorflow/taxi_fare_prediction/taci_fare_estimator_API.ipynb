{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Machine Learning using tf.estimator </h1>\n",
    "\n",
    "In this notebook, we will create a machine learning model using tf.estimator and evaluate its performance.  The dataset is rather small (7700 samples), so we can do it all in-memory.  We will also simply pass the raw data in as-is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "0.22.0\n",
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print(tf.__version__)\n",
    "print(pd.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data created in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In CSV, label is the first column, after the features, followed by the key\n",
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS) - 1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "\n",
    "df_train = pd.read_csv('./taxi-train.csv', header = None, names = CSV_COLUMNS)\n",
    "df_valid = pd.read_csv('./taxi-valid.csv', header = None, names = CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input function to read from Pandas Dataframe into tf.constant </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature columns for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "  input_columns = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression with tf.Estimator framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_evaluation_master': '', '_save_checkpoints_steps': None, '_model_dir': 'taxi_trained', '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0dcee649b0>, '_is_chief': True, '_task_type': 'worker', '_task_id': 0, '_master': '', '_service': None, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_save_checkpoints_secs': 600, '_train_distribute': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 30401.672\n",
      "INFO:tensorflow:global_step/sec: 240.77\n",
      "INFO:tensorflow:step = 101, loss = 6480.788 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 356.445\n",
      "INFO:tensorflow:step = 201, loss = 14720.842 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.133\n",
      "INFO:tensorflow:step = 301, loss = 6805.0283 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.364\n",
      "INFO:tensorflow:step = 401, loss = 9011.3955 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.971\n",
      "INFO:tensorflow:step = 501, loss = 13191.621 (0.312 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 573 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5512.163.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7f0e0ce958d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the validation data (we should defer using the test data to after we have selected a final model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-20-13:12:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-573\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-20-13:12:20\n",
      "INFO:tensorflow:Saving dict for global step 573: average_loss = 95.619965, global_step = 573, loss = 11555.306\n",
      "RMSE on validation dataset = 9.778546333312988\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, name, df):\n",
    "  metrics = model.evaluate(input_fn = make_input_fn(df, 1))\n",
    "  print('RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['average_loss'])))\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nowhere near our benchmark (RMSE of $6 or so on this data), but it serves to demonstrate what TensorFlow code looks like.  Let's use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_evaluation_master': '', '_save_checkpoints_steps': None, '_model_dir': 'taxi_trained', '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0dcc71ee48>, '_is_chief': True, '_task_type': 'worker', '_task_id': 0, '_master': '', '_service': None, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_save_checkpoints_secs': 600, '_train_distribute': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-573\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[10.308869, 10.664921, 10.308402, 10.186621, 10.18706]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# Read saved model and use it for prediction\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "preds_iter = model.predict(input_fn = make_input_fn(df_valid, 1))\n",
    "print([pred['predictions'][0] for pred in list(itertools.islice(preds_iter, 5))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explains why the RMSE was so high -- the model essentially predicts the same amount for every trip.  Would a more complex model help? Let's try using a deep neural network.  The code to do this is quite straightforward as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_tf_random_seed': None, '_evaluation_master': '', '_save_checkpoints_steps': None, '_model_dir': 'taxi_trained', '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_num_worker_replicas': 1, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0dcc597198>, '_is_chief': True, '_task_type': 'worker', '_task_id': 0, '_master': '', '_service': None, '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_save_checkpoints_secs': 600, '_train_distribute': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 166321.2\n",
      "INFO:tensorflow:global_step/sec: 253.958\n",
      "INFO:tensorflow:step = 101, loss = 28428.498 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.91\n",
      "INFO:tensorflow:step = 201, loss = 21443.594 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.784\n",
      "INFO:tensorflow:step = 301, loss = 16018.334 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.227\n",
      "INFO:tensorflow:step = 401, loss = 18570.406 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.722\n",
      "INFO:tensorflow:step = 501, loss = 33355.758 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.433\n",
      "INFO:tensorflow:step = 601, loss = 30270.031 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.026\n",
      "INFO:tensorflow:step = 701, loss = 23214.232 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.809\n",
      "INFO:tensorflow:step = 801, loss = 32176.938 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.831\n",
      "INFO:tensorflow:step = 901, loss = 19645.309 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.261\n",
      "INFO:tensorflow:step = 1001, loss = 15476.662 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.346\n",
      "INFO:tensorflow:step = 1101, loss = 21871.842 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.342\n",
      "INFO:tensorflow:step = 1201, loss = 17350.395 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.749\n",
      "INFO:tensorflow:step = 1301, loss = 34853.46 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.819\n",
      "INFO:tensorflow:step = 1401, loss = 19053.863 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.199\n",
      "INFO:tensorflow:step = 1501, loss = 16614.635 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.054\n",
      "INFO:tensorflow:step = 1601, loss = 15692.373 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.857\n",
      "INFO:tensorflow:step = 1701, loss = 23205.133 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.976\n",
      "INFO:tensorflow:step = 1801, loss = 9225.353 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.175\n",
      "INFO:tensorflow:step = 1901, loss = 34028.234 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.759\n",
      "INFO:tensorflow:step = 2001, loss = 20094.727 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.13\n",
      "INFO:tensorflow:step = 2101, loss = 14296.369 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.201\n",
      "INFO:tensorflow:step = 2201, loss = 14327.838 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.821\n",
      "INFO:tensorflow:step = 2301, loss = 11039.738 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.294\n",
      "INFO:tensorflow:step = 2401, loss = 17642.762 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.502\n",
      "INFO:tensorflow:step = 2501, loss = 17271.623 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.149\n",
      "INFO:tensorflow:step = 2601, loss = 12308.495 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.829\n",
      "INFO:tensorflow:step = 2701, loss = 16935.492 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.567\n",
      "INFO:tensorflow:step = 2801, loss = 21386.48 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.409\n",
      "INFO:tensorflow:step = 2901, loss = 17303.531 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.138\n",
      "INFO:tensorflow:step = 3001, loss = 8200.324 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.451\n",
      "INFO:tensorflow:step = 3101, loss = 8831.373 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.664\n",
      "INFO:tensorflow:step = 3201, loss = 11744.837 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.109\n",
      "INFO:tensorflow:step = 3301, loss = 16804.043 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.648\n",
      "INFO:tensorflow:step = 3401, loss = 26857.996 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.491\n",
      "INFO:tensorflow:step = 3501, loss = 16061.817 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.579\n",
      "INFO:tensorflow:step = 3601, loss = 18143.299 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.867\n",
      "INFO:tensorflow:step = 3701, loss = 9605.824 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.752\n",
      "INFO:tensorflow:step = 3801, loss = 20154.695 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.923\n",
      "INFO:tensorflow:step = 3901, loss = 45482.867 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.76\n",
      "INFO:tensorflow:step = 4001, loss = 20073.55 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.583\n",
      "INFO:tensorflow:step = 4101, loss = 10302.148 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.998\n",
      "INFO:tensorflow:step = 4201, loss = 10587.491 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 319.485\n",
      "INFO:tensorflow:step = 4301, loss = 13065.256 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.909\n",
      "INFO:tensorflow:step = 4401, loss = 15984.279 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.086\n",
      "INFO:tensorflow:step = 4501, loss = 18319.238 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.812\n",
      "INFO:tensorflow:step = 4601, loss = 10663.852 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.624\n",
      "INFO:tensorflow:step = 4701, loss = 14400.776 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.206\n",
      "INFO:tensorflow:step = 4801, loss = 17928.6 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.411\n",
      "INFO:tensorflow:step = 4901, loss = 9612.394 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.34\n",
      "INFO:tensorflow:step = 5001, loss = 18341.04 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.61\n",
      "INFO:tensorflow:step = 5101, loss = 13483.73 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.089\n",
      "INFO:tensorflow:step = 5201, loss = 20440.297 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.26\n",
      "INFO:tensorflow:step = 5301, loss = 15898.789 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.306\n",
      "INFO:tensorflow:step = 5401, loss = 20892.797 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.99\n",
      "INFO:tensorflow:step = 5501, loss = 11915.064 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.551\n",
      "INFO:tensorflow:step = 5601, loss = 9593.135 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.635\n",
      "INFO:tensorflow:step = 5701, loss = 12202.045 (0.313 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5729 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7687.924.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-20-13:14:59\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-5729\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-20-13:14:59\n",
      "INFO:tensorflow:Saving dict for global step 5729: average_loss = 120.20115, global_step = 5729, loss = 14525.846\n",
      "RMSE on validation dataset = 10.963628768920898\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units = [32, 8, 2],\n",
    "      feature_columns = make_feature_cols(), model_dir = OUTDIR)\n",
    "model.train(input_fn = make_input_fn(df_train, num_epochs = 100));\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not beating our benchmark with either model ... what's up?  Well, we may be using TensorFlow for Machine Learning, but we are not yet using it well.  That's what the rest of this course is about!\n",
    "\n",
    "But, for the record, let's say we had to choose between the two models. We'd choose the one with the lower validation error. Finally, we'd measure the RMSE on the test data with this chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Benchmark dataset </h2>\n",
    "\n",
    "Let's do this on the benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datalab.bigquery as bq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1 = train 2 = valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  CONCAT(STRING(pickup_datetime), STRING(pickup_longitude), STRING(pickup_latitude), STRING(dropoff_latitude), STRING(dropoff_longitude)) AS key,\n",
    "  DAYOFWEEK(pickup_datetime)*1.0 AS dayofweek,\n",
    "  HOUR(pickup_datetime)*1.0 AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count*1.0 AS passengers,\n",
    "FROM\n",
    "  [nyc-tlc:yellow.trips]\n",
    "WHERE\n",
    "  trip_distance > 0\n",
    "  AND fare_amount >= 2.5\n",
    "  AND pickup_longitude > -78\n",
    "  AND pickup_longitude < -70\n",
    "  AND dropoff_longitude > -78\n",
    "  AND dropoff_longitude < -70\n",
    "  AND pickup_latitude > 37\n",
    "  AND pickup_latitude < 45\n",
    "  AND dropoff_latitude > 37\n",
    "  AND dropoff_latitude < 45\n",
    "  AND passenger_count > 0\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # Training\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 < 2\".format(base_query)\n",
    "    else:\n",
    "      # Validation\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 == {1}\".format(base_query, phase)\n",
    "  else:\n",
    "    query = \"{0} AND ABS(HASH(pickup_datetime)) % {1} == {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "df = bq.Query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-20-13:16:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-5729\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-20-13:16:06\n",
      "INFO:tensorflow:Saving dict for global step 5729: average_loss = 114.11343, global_step = 5729, loss = 14504.109\n",
      "RMSE on benchmark dataset = 10.682388305664062\n"
     ]
    }
   ],
   "source": [
    "print_rmse(model, 'benchmark', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE on benchmark dataset is <b>10.68</b> (your results will vary because of random seeds).\n",
    "\n",
    "This is not only way more than our original benchmark of 6.00, but it doesn't even beat our distance-based rule's RMSE of 8.02.\n",
    "\n",
    "Fear not -- you have learned how to write a TensorFlow model, but not to do all the things that you will have to do to your ML model performant. We will do this in the next chapters. In this chapter though, we will get our TensorFlow model ready for these improvements.\n",
    "\n",
    "In a software sense, the rest of the labs in this chapter will be about refactoring the code so that we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
